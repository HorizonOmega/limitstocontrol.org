<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Statement - Limits to Control Workshop 2025</title>
    <link href="https://fonts.googleapis.com/css2?family=Lato:wght@400;700&family=Roboto+Slab:wght@400;700&display=swap" rel="stylesheet">
    <link href="main.css" rel="stylesheet">
</head>

<body>
    <header class="hero">
        <h1>Limits to Control Workshop 2025</h1>
    </header>

    <main class="container">
        <section id="statement">
            <h2>Statement from the Limits to Control Workshop</h2>
            <p>The 2025 Limits to Control Workshop convened a diverse cohort of leading researchers, to rigorously examine the boundaries of control over AI systems - defined as the reliable capacity to constrain AI behavior to intended outcomes through any combination of technical and institutional measures. While other actors work on developing new control techniques, we examine the theoretical foundations - what control can and cannot achieve in principle, and what fundamental aspects dictate where these boundaries lie. Our research should inform anyone in the community who wants to preserve human capacity for self-determination.</p>

            <p>In this statement, we articulate the collective worldview that emerged from the workshop, grounded in our initial research. Forthcoming research papers will provide rigorous definitions of the concepts discussed here, and will be the basis of further academic discussion.</p>

            <p>Across all sessions, a consensus emerged: as AI systems scale in their capacities to operate autonomously, meaningful control eventually becomes not merely difficult, but fundamentally impossible in principle. Our participants presented compelling results — theoretical arguments, formal impossibility proofs, and empirical demonstrations — showing that no combination of technical safeguards, interpretability tools, or regulatory oversight could constrain a fully autonomous AI to reliably safe behavior.</p>

            <p>Many questions remain under-explored. How do the limits of AI controllability shift with agent capabilities, possible degrees of oversight, or world complexity? We lack the quantitative evidence needed to identify danger zones where AI systems cannot be contained. There is also a need to verify threat models of self-modification, where an artificial system recursively learns and adapts across contexts. Future research should aim to inform policy, so governments do not lose power to runaway tech. It is only with informed governance that we can ensure that AI does not come at the cost of displacing human choice.</p>

            <p>This workshop marks an inflection point. In a nutshell: critical controllability thresholds exist, we don't know exactly where they are, and we cannot assume that meaningful control will remain feasible. Rather than perpetuate an illusion of control, the global community must now recognise the full threat of permanently losing control over humanity's future — leaving us as powerless to direct our fate as animals are to influence theirs in a human-dominated world. There are inherent limits to control, and as we push for increasing capabilities, we might cross the line before we realize it. We must fundamentally rethink how we address such risks.</p>

            <p>We thank all contributors for their uncompromising intellectual honesty and commitment to facing hard truths. The future of civilization may hinge on whether we can learn to accept and respect the boundaries of control.</p>

            <hr>

            <h3>Workshop participants:</h3>
            <ul>
                <li>Prof. Roman Yampolskiy</li>
                <li>Dr. Anders Sandberg</li>
                <li>Thibaud Veron</li>
                <li>Aybars Kocoglu</li>
                <li>Forrest Landry</li>
                <li>Richard Everheart</li>
                <li>Remmelt Ellen</li>
                <li>Will Petillo</li>
            </ul>
        </section>
    </main>

    <div class="statement-card">
        <a href="index.html">
            <h2>← Back to Home</h2>
            <p>Return to the workshop homepage</p>
        </a>
    </div>

    <footer>
        <p>&copy; 2025 Limits to Control Workshop. All rights reserved.</p>
    </footer>

</body>

</html>

